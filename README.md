# GitHub Actions Runner for Docker and Kubernetes

Self-hosted GitHub Actions runner for deployment in Kubernetes. The runner can
also be run locally, connected directly to the host docker daemon.

## Prerequisites

1. The runner automatically requests runner tokens via the GitHub APIs:
    1. For personal repositories, you must create a GitHub Personal Access
    Token (PAT) with _repo access_ permissons to the runner, and configure
    separate runners for each repository.
    2. For Organization you must create a GitHub App with read access to _
    organization self hosted runners_, and record the AppId. You must then
    create and download a private key for the App. Finally you must install
    the newly created App in GitHub, reload the browser and record the
    installation id from the browser location (see GitHub documentation for
    more information).
2. For Kubernets, `kubectl` must be configured to access the appropriate cluster
   context (in ~/.kube/config)

## TL;DR

### Run locally in docker with Personal Access Token

1. Copy `Auth/auth.json` and edit the `PersonalAccessToken`.

```sh
./deploy-actions-runner --config auth.json --owner you \
  --repository your/repo --docker | bash
```

### Deploy to Kubernetes

1. Copy `Auth/auth.json` and edit `AppId` and `InstallationId`
2. `Owner` should be set to the Organization wher the App is installed.
3. `PrivateKeyPath` should be left unchanged.

```sh
./deploy-actions-runner --config auth.json --owner acme | kubectl apply -f -
```

## Authentication

Runner tokens generated by GitHub are only valid for 60 minutes. New runner
tokens must in practice be generated every time a new runner is
started.

The project includes a small tool to get runner tokens from GitHub.
It can authenticate either using PATs or as a GitHub App. In App mode, it can
be used to start organization wide runners.

## Build

The provided Dockerfile will build a docker image with the authentication tool
and actions runnner installed.

### Plain runner

To build a minimal Docker image, with just the runner and authentication tool:

```sh
docker build -t actions-runner:latest --target runner .
```

### Runner with .NET Core 3.1, Node 12, yarn and headless Chrome

To build a runner image for use with the F# SAFE-Template for web
development:

```sh
docker build -t actions-runner-safe:latest .
```

## Motivation

The self hosted GitHub Actions runner is designed to run in a VM or directly on
a host OS. In order to run on on Kubernetes we must containerize the runner. In
itself, this is pretty simple. But complications arise when we want to support
runnering containers on the runner. This is necessary for two reasons: 1) Many
Marketplace actions run in containers 2) consistent build environments using
containers.

This project tries to hide most of the complications, but still
requires a bit of systems knowledge, and some basic Kubernetes skills.

The project also makes it easy to run GitHub Actions in a container locally.

## Implementation

Running containers in a container can be achieved using Docker-in-Docker (dind).
However, this is complicated by the the need to share volumes from within the
"parent" container. The dind instance is running on top of a local dockerd,
which knows nothing of the interal structure inside the container. A "child"
continer started within a container, is actually not a child, but a sibling.
Both containers run side by side on the same system level `dockerd`. Thus, in
order to share volumes, the volume must be created and shared at the systems
level. This complicated things somewhat.

Another complication is that the action runner runs with UID 1000, but any
containers it starts, might run as root. This can easily mess up file
permissions on shared volumes, so please make sure to reset permissions before
exit.

### Kubernetes

The Kubernetes deployment relies on `kubectl` being configured correctly on the
executing system. The provided YAML objects are customized using a Kustomization
object.

The Deployment object uses Kubernetes lifecycle management with a preStop hook
to cleanly remove runners.

#### Helm deployments to Kubernetes

You can manage deployments to Kubernetes using Helm and a self-hosted runner,
using the following Workflow recipe:

```yaml
deploy-staging:
  container: dtzar/helm-kubectl:latest
  runs-on: self-hosted
  needs: release
  env:
    KUBE_INSTANCE: cluster1
    KUBE_NAMESPACE: default
    DEPLOY_NAME: myapp
  steps:
  - uses: actions/checkout@v2
  - name: Deploy
    run: |
      mkdir -p $HOME/.kube
      echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > $HOME/.kube/config
      kubectl config use-context $KUBE_INSTANCE
      kubectl get pods -n $KUBE_NAMESPACE
      helm list -n $KUBE_NAMESPACE
      cmd=upgrade && helm list -q -n $KUBE_NAMESPACE | grep -q "$DEPLOY_NAME" || cmd=install
      echo "helm $cmd $DEPLOY_NAME"
      helm $cmd -f ./charts/values.yaml \
          --namespace $KUBE_NAMESPACE \
          $DEPLOY_NAME ./charts
  - name: Cleanup
    run: |
      chown -R 1000:1000 .
```

## Security

The Kubernetes Deployment runs a `dind` side-car container in privileged mode,
to support running docker commands and containerized actions in a container.
*This has security implications, which should be considered and understood
before use!*

## Note on local docker instances

The runners can easily be run locally on any host with runing `dockerd`. Please
note that you might have to pass in an environment variable `HOST_DOCKER_GID`
with the GID of the docker socket, in order to have access permissions within
the container.
